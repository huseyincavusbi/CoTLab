{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CoTLab Tutorial\n",
    "\n",
    "**CoTLab** is a research toolkit for studying Chain-of-Thought (CoT) reasoning in LLMs.\n",
    "\n",
    "In this tutorial you will learn to:\n",
    "1. Load a model with CoTLab's backend system\n",
    "2. Run experiments using CoTLab's experiment API\n",
    "3. Log and save results with ExperimentLogger\n",
    "4. Analyze results with the analysis module\n",
    "\n",
    "> **Note**: We use GPT-2 here for fast demo. For real experiments, use larger models like MedGemma."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"  # Suppress HF warning\n",
    "\n",
    "from cotlab.backends import TransformersBackend\n",
    "from cotlab.datasets.loaders import TutorialDataset\n",
    "from cotlab.experiments import CoTFaithfulnessExperiment\n",
    "from cotlab.logging import ExperimentLogger\n",
    "from cotlab.prompts.strategies import (\n",
    "    ChainOfThoughtStrategy,\n",
    "    ContrarianStrategy,\n",
    "    DirectAnswerStrategy,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Backend and Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Device map: auto\n",
      "  Dtype: torch.bfloat16\n",
      "  Cache: ~/.cache/huggingface (HF default)\n",
      "  Resolved device: mps\n",
      "Dataset: 10 samples\n"
     ]
    }
   ],
   "source": [
    "# Create backend and load model\n",
    "backend = TransformersBackend(device=\"auto\", dtype=\"bfloat16\")\n",
    "backend.load_model(\"openai-community/gpt2\")\n",
    "\n",
    "# Load dataset\n",
    "dataset = TutorialDataset(path=\"../data/tutorial.json\")\n",
    "print(f\"Dataset: {len(dataset)} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Define Experiment and Strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment: tutorial_comparison\n",
      "Strategies: ['contrarian', 'chain_of_thought', 'direct_answer']\n"
     ]
    }
   ],
   "source": [
    "# Create CoTLab experiment (uses all samples by default)\n",
    "experiment = CoTFaithfulnessExperiment(\n",
    "    name=\"tutorial_comparison\",\n",
    ")\n",
    "\n",
    "# Define prompting strategies\n",
    "strategies = {\n",
    "    \"contrarian\": ContrarianStrategy(),\n",
    "    \"chain_of_thought\": ChainOfThoughtStrategy(),\n",
    "    \"direct_answer\": DirectAnswerStrategy(),\n",
    "}\n",
    "\n",
    "print(f\"Experiment: {experiment.name}\")\n",
    "print(f\"Strategies: {list(strategies.keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Run Experiments with Logging\n",
    "\n",
    "Use CoTLab's `ExperimentLogger` to save results to JSON files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Running: contrarian\n",
      "============================================================\n",
      "Running Faithfulness Test: contrarian vs direct_answer\n",
      "Generating contrarian responses...\n",
      "Generating direct_answer responses...\n",
      "Analyzing results...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing samples: 100%|██████████| 10/10 [00:00<00:00, 16422.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to: ../outputs/tutorial_contrarian/results.json\n",
      "\n",
      "============================================================\n",
      "Running: chain_of_thought\n",
      "============================================================\n",
      "Running Faithfulness Test: chain_of_thought vs direct_answer\n",
      "Generating chain_of_thought responses...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating direct_answer responses...\n",
      "Analyzing results...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing samples: 100%|██████████| 10/10 [00:00<00:00, 28630.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to: ../outputs/tutorial_chain_of_thought/results.json\n",
      "\n",
      "============================================================\n",
      "Running: direct_answer\n",
      "============================================================\n",
      "Running Faithfulness Test: direct_answer vs direct_answer\n",
      "Generating direct_answer responses...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating direct_answer responses...\n",
      "Analyzing results...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing samples: 100%|██████████| 10/10 [00:00<00:00, 131896.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to: ../outputs/tutorial_direct_answer/results.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "results = {}\n",
    "\n",
    "for name, strategy in strategies.items():\n",
    "    print(f\"\\n{'=' * 60}\")\n",
    "    print(f\"Running: {name}\")\n",
    "    print(f\"{'=' * 60}\")\n",
    "\n",
    "    # Create logger for this run\n",
    "    logger = ExperimentLogger(f\"../outputs/tutorial_{name}\")\n",
    "\n",
    "    # Log configuration\n",
    "    logger.log_config(\n",
    "        {\n",
    "            \"experiment\": experiment.name,\n",
    "            \"strategy\": name,\n",
    "            \"model\": \"gpt2\",\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Run CoTLab experiment with logger (uses all samples)\n",
    "    result = experiment.run(\n",
    "        backend=backend,\n",
    "        dataset=dataset,\n",
    "        prompt_strategy=strategy,\n",
    "        logger=logger,\n",
    "    )\n",
    "\n",
    "    # Save results using logger\n",
    "    output_path = logger.save_results(result)\n",
    "    print(f\"Results saved to: {output_path}\")\n",
    "\n",
    "    results[name] = result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Analyze Results with CoTLab Analysis Module\n",
    "\n",
    "Use `analyse_experiments` for proper answer extraction and comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Tutorial Experiment Analysis\n",
      "================================================================================\n",
      "\n",
      "COT FAITHFULNESS EXPERIMENTS\n",
      "----------------------------------------\n",
      "Prompt                      Agree%  CoT Acc Direct Acc  Samples\n",
      "------------------------------------------------------------\n",
      "chain_of_thought              0.0%     0.0%      10.0%       10\n",
      "contrarian                   20.0%    10.0%      20.0%       10\n",
      "direct_answer                 0.0%    10.0%       0.0%       10\n",
      "\n",
      "================================================================================\n",
      "SUMMARY BY DATASET\n",
      "================================================================================\n",
      "Dataset                Agree%  CoT Acc Direct Acc  Samples\n",
      "-------------------------------------------------------\n",
      "tutorial                 6.7%     6.7%      10.0%       30\n",
      "\n",
      "OVERALL (Faithfulness): 30 samples\n",
      "  - Agreement: 6.7%\n",
      "  - CoT Accuracy: 6.7%\n",
      "  - Direct Accuracy: 10.0%\n"
     ]
    }
   ],
   "source": [
    "from cotlab.analyse_experiments import (\n",
    "    analyse_experiments_dir,\n",
    "    export_to_csv,\n",
    "    print_analysis_report,\n",
    ")\n",
    "\n",
    "# Analyze all saved results\n",
    "results_dir = Path(\"../outputs\")\n",
    "all_results = analyse_experiments_dir(results_dir)\n",
    "\n",
    "# Print comprehensive analysis report\n",
    "print_analysis_report(all_results, \"Tutorial Experiment Analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Export Results to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results saved to: ../outputs/tutorial_analysis.csv\n",
      "\n",
      "CSV exported to: ../outputs/tutorial_analysis.csv\n"
     ]
    }
   ],
   "source": [
    "# Export analysis to CSV for further processing\n",
    "csv_path = results_dir / \"tutorial_analysis.csv\"\n",
    "export_to_csv(all_results, csv_path)\n",
    "\n",
    "print(f\"\\nCSV exported to: {csv_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Next Steps\n",
    "\n",
    "**Other CoTLab experiments**:\n",
    "- `LogitLensExperiment` - See what model \"thinks\" at each layer\n",
    "- `AttentionAnalysisExperiment` - Analyze attention patterns\n",
    "- `ProbingClassifierExperiment` - Train probes on hidden states\n",
    "\n",
    "**For future use**:\n",
    "- Use `python -m cotlab.runner` CLI with Hydra configs\n",
    "- See `conf/` folder for configuration options\n",
    "- Use larger models: `google/medgemma-27b-text-it`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cotlab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
