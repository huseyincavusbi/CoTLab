# Base template for Transformers models
# Use for mechanistic experiments
# Example: cp conf/model/_base/transformers_default.yaml conf/model/my_model.yaml

# REQUIRED: Change to your model name
name: "huggingface/model-name"

backend: transformers

# Inference parameters
max_tokens: 2048
temperature: 0.0
top_p: 1.0
do_sample: false

# Transformers specific settings
device_map: auto
torch_dtype: auto
trust_remote_code: true
use_flash_attention: true

# WARNING: Mechanistic experiments require standard Transformer architecture
# May be fail with models with MoE, SSM, or hybrid architectures
