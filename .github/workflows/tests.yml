name: Tests

on:
  push:
    branches: [main]
  pull_request:
    branches: [main]

jobs:
  unit-tests:
    runs-on: ${{ matrix.os }}
    strategy:
      matrix:
        os: [ubuntu-latest, macos-latest]
        python-version: ["3.11", "3.12", "3.13"]

    steps:
      - uses: actions/checkout@v4

      - name: Free disk space (Linux)
        if: runner.os == 'Linux'
        run: |
          echo "Disk space before cleanup:"
          df -h
          sudo rm -rf /usr/share/dotnet
          sudo rm -rf /usr/local/lib/android
          sudo rm -rf /opt/ghc
          sudo rm -rf /opt/hostedtoolcache/CodeQL
          echo "Disk space after cleanup:"
          df -h

      - name: Print runner info
        run: |
          if [[ "$OSTYPE" == "darwin"* ]]; then
            sysctl -n machdep.cpu.brand_string || echo "Unknown CPU"
          else
            cat /proc/cpuinfo | grep "model name" | head -1 || echo "Unknown CPU"
          fi

      - name: Setup micromamba
        uses: mamba-org/setup-micromamba@v2
        with:
          micromamba-version: "2.0.5-0"
          environment-name: cotlab
          create-args: >-
            python=${{ matrix.python-version }}
            pip
          init-shell: bash

      - name: Install dependencies
        shell: bash -el {0}
        run: |
          pip install -e ".[dev]"

      - name: Run unit tests
        shell: bash -el {0}
        run: |
          python -m pytest tests/ -v --tb=short

  integration:
    runs-on: ${{ matrix.os }}
    strategy:
      matrix:
        os: [ubuntu-latest, macos-latest]
    steps:
      - uses: actions/checkout@v4

      - name: Free disk space (Linux)
        if: runner.os == 'Linux'
        run: |
          sudo rm -rf /usr/share/dotnet /usr/local/lib/android /opt/ghc /opt/hostedtoolcache/CodeQL

      - name: Setup micromamba
        uses: mamba-org/setup-micromamba@v2
        with:
          micromamba-version: "2.0.5-0"
          environment-name: cotlab
          create-args: >-
            python=3.11
            pip
          init-shell: bash

      - name: Install dependencies
        shell: bash -el {0}
        run: |
          pip install -e ".[dev]"

      - name: Test framework imports
        shell: bash -el {0}
        run: |
          python -c "
          from cotlab import __version__
          from cotlab.backends import TransformersBackend
          from cotlab.experiments import (
              CoTFaithfulnessExperiment,
              RadiologyExperiment,
              CoTAblationExperiment,
              ActivationPatchingExperiment,
              SycophancyHeadsExperiment,
              MultiHeadPatchingExperiment,
              FullLayerPatchingExperiment,
              SteeringVectorsExperiment,
              CoTHeadsExperiment,
              LogitLensExperiment,
              MultiHeadCoTExperiment,
          )
          from cotlab.prompts import ChainOfThoughtStrategy, RadiologyPromptStrategy, CardiologyPromptStrategy, NeurologyPromptStrategy, OncologyPromptStrategy
          from cotlab.datasets import RadiologyDataset, SyntheticMedicalDataset, CardiologyDataset, NeurologyDataset, OncologyDataset
          from cotlab.analysis import CoTParser, FaithfulnessMetrics
          from cotlab.patching import ActivationPatcher

          print(f'CoTLab v{__version__} - All 12 experiments available!')
          "

      - name: Test prompt strategies
        shell: bash -el {0}
        run: |
          python -c "
          from cotlab.prompts import create_prompt_strategy

          strategies = [
              'simple', 'chain_of_thought', 'direct_answer', 'arrogance', 'no_instruction',
              'adversarial', 'uncertainty', 'socratic', 'contrarian', 'expert_persona',
              'sycophantic', 'few_shot'
          ]
          for name in strategies:
              s = create_prompt_strategy(name)
              prompt = s.build_prompt({'question': 'Test question?'})
              print(f'{name}: {len(prompt)} chars')

          print(f'All {len(strategies)} prompt strategies work!')
          "

      - name: Test dataset loading
        shell: bash -el {0}
        run: |
          python -c "
          from cotlab.datasets import SyntheticMedicalDataset, RadiologyDataset, CardiologyDataset, NeurologyDataset, OncologyDataset

          for Dataset in [SyntheticMedicalDataset, RadiologyDataset, CardiologyDataset, NeurologyDataset, OncologyDataset]:
              dataset = Dataset()
              print(f'{Dataset.__name__}: {len(dataset)} samples')

          print('All 5 datasets load correctly!')
          "

      - name: Test CoT parser
        shell: bash -el {0}
        run: |
          python -c "
          from cotlab.analysis import CoTParser

          parser = CoTParser()
          cot = '''
          1. Patient has fever
          2. Symptoms suggest infection
          Therefore, likely viral URI.
          '''

          result = parser.analyze(cot)
          print(f'Steps: {result[\"num_steps\"]}')
          print(f'Conclusion: {result[\"conclusion\"]}')
          print('CoT parser works!')
          "

      - name: Test new prompt features (answer_first, few_shot, contrarian)
        shell: bash -el {0}
        run: |
          python -c "
          from cotlab.prompts import RadiologyPromptStrategy, CardiologyPromptStrategy

          # Test answer_first mode
          answer_first = RadiologyPromptStrategy(answer_first=True)
          af_prompt = answer_first.build_prompt({'report': 'Test'})
          assert 'Initial' in af_prompt, 'answer_first prompt should contain Initial Assessment'
          print('answer_first mode works')

          # Test few_shot=false (example removal)
          with_examples = RadiologyPromptStrategy(few_shot=True)
          without_examples = RadiologyPromptStrategy(few_shot=False)
          text_with = with_examples.build_prompt({'report': 'Test'})
          text_without = without_examples.build_prompt({'report': 'Test'})
          assert 'Example 1:' in text_with, 'Should have examples when few_shot=true'
          assert 'Example 1:' not in text_without, 'Should not have examples when few_shot=false'
          assert len(text_without) < len(text_with), 'Prompt without examples should be shorter'
          print('few_shot parameter works')

          # Test contrarian mode
          standard = RadiologyPromptStrategy(contrarian=False)
          contrarian = RadiologyPromptStrategy(contrarian=True)
          std_prompt = standard.build_prompt({'report': 'Test'})
          con_prompt = contrarian.build_prompt({'report': 'Test'})
          assert std_prompt != con_prompt, 'Contrarian prompt should differ from standard'
          print('contrarian mode works')

          # Test combinations work across specialties
          for Strategy in [RadiologyPromptStrategy, CardiologyPromptStrategy]:
              s = Strategy(answer_first=True, few_shot=False)
              prompt = s.build_prompt({'report': 'Test'})
              assert 'Initial' in prompt and 'Example 1:' not in prompt
          print('Parameter combinations work across specialties')
          "

  notebook-test:
    runs-on: ${{ matrix.os }}
    strategy:
      matrix:
        os: [ubuntu-latest, macos-latest]
    steps:
      - uses: actions/checkout@v4

      - name: Free disk space (Linux)
        if: runner.os == 'Linux'
        run: |
          sudo rm -rf /usr/share/dotnet /usr/local/lib/android /opt/ghc /opt/hostedtoolcache/CodeQL

      - name: Setup micromamba
        uses: mamba-org/setup-micromamba@v2
        with:
          micromamba-version: "2.0.5-0"
          environment-name: cotlab
          create-args: >-
            python=3.11
            pip
            papermill
            ipykernel
          init-shell: bash

      - name: Install dependencies
        shell: bash -el {0}
        run: |
          pip install -e ".[dev]"
          python -m ipykernel install --user --name cotlab --display-name "CoTLab"

      - name: Execute tutorial notebook
        shell: bash -el {0}
        run: |
          echo "Running notebook: cotlab_tutorial.ipynb (CI mode: 5 samples, 64 max_tokens)"
          cd notebooks
          papermill cotlab_tutorial.ipynb cotlab_tutorial_executed.ipynb -k cotlab --progress-bar -p NUM_SAMPLES 5 -p MAX_TOKENS 64
          echo "Notebook executed successfully on ${{ matrix.os }}!"
